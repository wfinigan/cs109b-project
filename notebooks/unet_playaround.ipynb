{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from unet_extras.zf_unet_224_model import ZF_UNET_224, dice_coef_loss, dice_coef\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import LambdaCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../clean_data'\n",
    "\n",
    "NUM_SAMPLES_TRAIN = 776\n",
    "\n",
    "TARGET_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet for General Mass Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 776 images belonging to 1 classes.\n",
      "Found 776 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# use same seed for images and masks\n",
    "seed = 109\n",
    "\n",
    "im_fit_datagen = ImageDataGenerator()\n",
    "im_fit_generator = im_fit_datagen.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/train/images',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=NUM_SAMPLES_TRAIN,\n",
    "    class_mode=None,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "mask_fit_datagen = ImageDataGenerator()\n",
    "mask_fit_generator = mask_fit_datagen.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/train/masks',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=NUM_SAMPLES_TRAIN,\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "images = next(im_fit_generator)\n",
    "masks = next(mask_fit_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 621 images belonging to 1 classes.\n",
      "Found 155 images belonging to 1 classes.\n",
      "Found 621 images belonging to 1 classes.\n",
      "Found 155 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# we create two instances with the same arguments\n",
    "data_gen_args = dict(rotation_range=45.,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,\n",
    "    fill_mode='constant',\n",
    "    validation_split=.2,\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "image_datagen.fit(images, augment=True, seed=seed)\n",
    "mask_datagen.fit(masks, augment=True, seed=seed)\n",
    "\n",
    "image_train_generator = image_datagen.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/train/images',\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    subset='training',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "image_val_generator = image_datagen.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/train/images',\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    subset='validation',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "mask_train_generator = mask_datagen.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/train/masks',\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    subset='training',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "mask_val_generator = mask_datagen.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/train/masks',\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    subset='validation',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "train_generator = zip(image_train_generator, mask_train_generator)\n",
    "val_generator = zip(image_val_generator, mask_val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 275 images belonging to 1 classes.\n",
      "Found 275 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator_image_test = ImageDataGenerator(rescale=1./255)\n",
    "data_generator_mask_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "image_test_generator = data_generator_image_test.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/test/images',\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "mask_test_generator = data_generator_mask_test.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/test/masks',\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    target_size=TARGET_SIZE\n",
    ")\n",
    "\n",
    "test_generator = zip(image_test_generator, mask_test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ZF_UNET_224(weights='generator')\n",
    "optim = Adam()\n",
    "\n",
    "for i in range(len(model.layers) - 6):\n",
    "    model.layers[i].trainable = False\n",
    "\n",
    "model.compile(optimizer=optim, loss=dice_coef_loss, metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_plot(epoch, logs):\n",
    "    pred_im, pred_mask = next(val_generator)\n",
    "    \n",
    "    preds = model.predict(pred_im)\n",
    "    \n",
    "    fig_im, ax_im = plt.subplots(1, 4, figsize=[8, 3])\n",
    "    fig_mask, ax_mask = plt.subplots(1, 4, figsize=[8, 3])\n",
    "    fig_pred, ax_pred = plt.subplots(1, 4, figsize=[8, 3])\n",
    "\n",
    "    for i in range(4):\n",
    "        ax_im[i].imshow(pred_im[i])\n",
    "        ax_mask[i].imshow(pred_mask[i].reshape(224, 224), cmap='gray')\n",
    "        ax_pred[i].imshow(preds[i].reshape(224, 224), cmap='gray')\n",
    "        \n",
    "#     fig_im.suptitle('Original images')\n",
    "#     fig_mask.suptitle('Ground truth mask')\n",
    "#     fig_pred.suptitle('Predicted Mask')\n",
    "    \n",
    "    fig_im.tight_layout()\n",
    "    fig_mask.tight_layout()\n",
    "    fig_pred.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 70/100 [====================>.........] - ETA: 9s - loss: -0.0731 - dice_coef: 0.0731"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=3,\n",
    "    callbacks=[LambdaCallback(on_epoch_end=callback_plot)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 18s 557ms/step\n",
      "32/32 [==============================] - 15s 472ms/step\n"
     ]
    }
   ],
   "source": [
    "model_untrained = ZF_UNET_224(weights='generator')\n",
    "model_untrained.compile(optimizer=optim, loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "# get batch of test images for plotting\n",
    "im, mask = next(test_generator)\n",
    "\n",
    "pred = model.predict(im, steps=len(im), verbose = 1)\n",
    "pred_untrained = model_untrained.predict(im, steps=len(im), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(ims, masks, preds, preds_untrained=None, index=0):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=[8, 4])\n",
    "    \n",
    "    ax[0].imshow(ims[index])\n",
    "    ax[1].imshow(masks[index].reshape(224, 224), cmap='gray')\n",
    "    ax[2].imshow(preds[index].reshape(224, 224), cmap='gray')\n",
    "\n",
    "    ax[0].set_title('Original image')\n",
    "    ax[1].set_title('True mask')\n",
    "    ax[2].set_title('Predicted mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-79becb1e0770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'show_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "show_predictions(im, mask, pred, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet for Malignant Mass Detection\n",
    "\n",
    "In this case, we want our UNET to only give masks for malignant masses. To do this, we will train using all black masses for benign samples and normal masks for malignant ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "\n",
    "We will do most of the same dataprep as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, get the masks in memory so that we can fit the image augmentation\n",
    "mask_bb_fit_datagen = ImageDataGenerator()\n",
    "mask_bb_fit_generator = mask_bb_fit_datagen.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/train/mask_blackbox',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=NUM_SAMPLES,\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "masks_bb = next(mask_bb_fit_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate our generators to ensure seed hasn't changed (using same args from above)\n",
    "image_bb_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_bb_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# use the same seed for masks and images throughout so they line up correctly\n",
    "seed = 1\n",
    "image_bb_datagen.fit(images, augment=True, seed=seed)\n",
    "mask_bb_datagen.fit(masks_bb, augment=True, seed=seed)\n",
    "\n",
    "image_bb_train_generator = image_bb_datagen.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/train/images',\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    subset='training',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "image_bb_val_generator = image_datagen.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/train/images',\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    subset='validation',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "mask_bb_train_generator = mask_bb_datagen.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/train/mask_blackbox',\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    subset='training',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "mask_bb_val_generator = mask_bb_datagen.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/train/mask_blackbox',\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    subset='validation',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "train_bb_generator = zip(image_bb_train_generator, mask_bb_train_generator)\n",
    "val_bb_generator = zip(image_bb_val_generator, mask_bb_val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recompile and Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ZF_UNET_224(weights='generator')\n",
    "\n",
    "for i in range(len(model.layers) - 6):\n",
    "    model.layers[i].trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=1500,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=150\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again need to recreate to ensure correct alignment\n",
    "data_generator_image_bb_test = ImageDataGenerator(rescale=1./255)\n",
    "data_generator_mask_bb_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "image_bb_test_generator = data_generator_image_bb_test.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/test/images',\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "mask_bb_test_generator = data_generator_mask_bb_test.flow_from_directory(\n",
    "    f'{DATA_DIR}/mass/test/mask_blackbox',\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    target_size=TARGET_SIZE\n",
    ")\n",
    "\n",
    "test_bb_generator = zip(image_bb_test_generator, mask_bb_test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
