{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed for our Cats & Dogs classes\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Fixed for Cats & Dogs color images\n",
    "CHANNELS = 3\n",
    "\n",
    "IMAGE_RESIZE = 224\n",
    "RESNET50_POOLING_AVERAGE = 'avg'\n",
    "DENSE_LAYER_ACTIVATION = 'softmax'\n",
    "OBJECTIVE_FUNCTION = 'binary_crossentropy'\n",
    "\n",
    "# Common accuracy metric for all outputs, but can use different metrics for different output\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
    "NUM_EPOCHS = 20\n",
    "#EARLY_STOP_PATIENCE = 3\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\n",
    "STEPS_PER_EPOCH_TRAINING = 24\n",
    "STEPS_PER_EPOCH_VALIDATION = 24\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\n",
    "BATCH_SIZE_TRAINING = 32\n",
    "BATCH_SIZE_VALIDATION = 32\n",
    "\n",
    "# Using 1 to easily manage mapping between test_generator & prediction for submission preparation\n",
    "BATCH_SIZE_TESTING = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Still not talking about our train/test data or any pre-processing.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
    "model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = resnet_weights_path))\n",
    "\n",
    "# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
    "model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
    "\n",
    "# Say not to train first layer (ResNet) model as it is already trained\n",
    "model.layers[0].trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import optimizers\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = IMAGE_RESIZE\n",
    "\n",
    "# preprocessing_function is applied on each image but only after re-sizing & augmentation (resize => augment => pre-process)\n",
    "# Each of the keras.application.resnet* preprocess_input MOSTLY mean BATCH NORMALIZATION (applied on each batch) stabilize the inputs to nonlinear activation functions\n",
    "# Batch Normalization helps in faster convergence\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../clean_data/mass/train/resnet_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   path  class\n",
       "0           0  0.tif      1\n",
       "1           1  1.tif      1\n",
       "2           2  2.tif      0\n",
       "3           3  3.tif      0\n",
       "4           4  4.tif      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 621 images belonging to 2 classes.\n",
      "Found 155 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# flow_From_directory generates batches of augmented data (where augmentation can be color conversion, etc)\n",
    "# Both train & valid folders must have NUM_CLASSES sub-folders\n",
    "\n",
    "train_generator = data_generator.flow_from_dataframe(train,\n",
    "                                                     directory = '../clean_data/mass/train/crops/',\n",
    "                                                     x_col = 'path',\n",
    "                                                     y_col = 'class',\n",
    "                                                     target_size= (image_size, image_size),\n",
    "                                                     batch_size = BATCH_SIZE_TRAINING,\n",
    "                                                     class_mode = 'categorical',\n",
    "                                                     subset = 'training')\n",
    "\n",
    "validation_generator = data_generator.flow_from_dataframe(train,\n",
    "                                                     directory = '../clean_data/mass/train/crops/',\n",
    "                                                     x_col = 'path',\n",
    "                                                     y_col = 'class',\n",
    "                                                     target_size= (image_size, image_size),\n",
    "                                                     batch_size = BATCH_SIZE_TRAINING,\n",
    "                                                     class_mode = 'categorical',\n",
    "                                                     subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max number of steps that these generator will have opportunity to process their source content\n",
    "# len(train_generator) should be 'no. of available train images / BATCH_SIZE_TRAINING'\n",
    "# len(valid_generator) should be 'no. of available train images / BATCH_SIZE_VALIDATION'\n",
    "#(BATCH_SIZE_TRAINING, len(train_generator), BATCH_SIZE_VALIDATION, len(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping & checkpointing the best model in ../working dir & restoring that as our model for prediction\n",
    "# from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n",
    "# cb_checkpointer = ModelCheckpoint(filepath = 'best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.grid_search import ParameterGrid\\nparam_grid = {'epochs': [5, 10, 15], 'steps_per_epoch' : [10, 20, 50]}\\n\\ngrid = ParameterGrid(param_grid)\\n\\n# Accumulate history of all permutations (may be for viewing trend) and keep watching for lowest val_loss as final model\\nfor params in grid:\\n    print(params)\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search is an ideal candidate for distributed machine learning\n",
    "# Pseudo code for hyperparameters Grid Search\n",
    "\n",
    "'''\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "param_grid = {'epochs': [5, 10, 15], 'steps_per_epoch' : [10, 20, 50]}\n",
    "\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "# Accumulate history of all permutations (may be for viewing trend) and keep watching for lowest val_loss as final model\n",
    "for params in grid:\n",
    "    print(params)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 16s 669ms/step - loss: 0.8794 - acc: 0.5607 - val_loss: 1.7752 - val_acc: 0.4786\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 11s 462ms/step - loss: 0.5419 - acc: 0.7440 - val_loss: 1.2720 - val_acc: 0.5134\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 11s 468ms/step - loss: 0.4545 - acc: 0.8003 - val_loss: 1.2946 - val_acc: 0.4853\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 11s 474ms/step - loss: 0.4377 - acc: 0.7917 - val_loss: 1.6033 - val_acc: 0.4733\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 11s 464ms/step - loss: 0.4810 - acc: 0.7808 - val_loss: 1.1559 - val_acc: 0.5294\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 11s 471ms/step - loss: 0.3259 - acc: 0.8626 - val_loss: 1.4223 - val_acc: 0.4893\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 11s 471ms/step - loss: 0.2685 - acc: 0.8978 - val_loss: 1.4068 - val_acc: 0.5027\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 11s 467ms/step - loss: 0.2685 - acc: 0.8987 - val_loss: 1.2373 - val_acc: 0.5401\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 11s 471ms/step - loss: 0.2933 - acc: 0.8738 - val_loss: 1.5417 - val_acc: 0.5147\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 11s 475ms/step - loss: 0.2416 - acc: 0.9038 - val_loss: 1.2801 - val_acc: 0.5160\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 11s 472ms/step - loss: 0.2512 - acc: 0.9128 - val_loss: 1.2577 - val_acc: 0.5040\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 11s 477ms/step - loss: 0.2033 - acc: 0.9427 - val_loss: 1.4034 - val_acc: 0.5094\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 11s 471ms/step - loss: 0.2012 - acc: 0.9275 - val_loss: 1.3795 - val_acc: 0.5027\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 11s 476ms/step - loss: 0.2026 - acc: 0.9304 - val_loss: 1.4171 - val_acc: 0.5094\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 11s 476ms/step - loss: 0.1818 - acc: 0.9486 - val_loss: 1.4501 - val_acc: 0.4987\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 11s 476ms/step - loss: 0.2117 - acc: 0.9181 - val_loss: 1.4295 - val_acc: 0.5094\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 11s 472ms/step - loss: 0.1885 - acc: 0.9363 - val_loss: 1.5248 - val_acc: 0.5000\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 11s 477ms/step - loss: 0.1612 - acc: 0.9505 - val_loss: 1.5354 - val_acc: 0.4973\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 11s 476ms/step - loss: 0.1745 - acc: 0.9403 - val_loss: 1.5697 - val_acc: 0.4786\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 11s 471ms/step - loss: 0.2023 - acc: 0.9272 - val_loss: 1.6395 - val_acc: 0.4920\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for best.hdf5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-34ff72e0ee97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#callbacks=[cb_checkpointer, cb_early_stopper]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1510\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m         \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1513\u001b[0m         \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLossError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m    324\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_api_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train.NewCheckpointReader'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for best.hdf5"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "        #callbacks=[cb_checkpointer, cb_early_stopper]\n",
    ")\n",
    "model.load_weights(\"best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_test = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('clean_data/mass/test/resnet_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE that flow_from_directory treats each sub-folder as a class which works fine for training data\n",
    "# Actually class_mode=None is a kind of workaround for test data which too must be kept in a subfolder\n",
    "\n",
    "# batch_size can be 1 or any factor of test dataset size to ensure that test dataset is samples just once, i.e., no data is left out\n",
    "test_generator = data_generator.flow_from_dataframe(test,\n",
    "                                                     directory = '../clean_data/mass/test/crops/',\n",
    "                                                     x_col = 'path',\n",
    "                                                     y_col = 'class',\n",
    "                                                     target_size= (image_size, image_size),\n",
    "                                                     batch_size = BATCH_SIZE_TRAINING,\n",
    "                                                     class_mode = 'categorical')\n",
    "\n",
    "# Try batch size of 1+ in test_generator & check batch_index & filenames in resulting batches\n",
    "'''\n",
    "for i in test_generator:\n",
    "    #print(test_generator.batch_index, test_generator.batch_size)\n",
    "    idx = (test_generator.batch_index - 1) * test_generator.batch_size\n",
    "    print(test_generator.filenames[idx : idx + test_generator.batch_size])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 386ms/step\n"
     ]
    }
   ],
   "source": [
    "# Reset before each call to predict\n",
    "test_generator.reset()\n",
    "\n",
    "pred = model.predict_generator(test_generator, steps = len(test_generator), verbose = 1)\n",
    "\n",
    "predicted_class_indices = np.argmax(pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False,  True,  True, False, False,  True,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False,  True,  True,  True,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "       False, False, False,  True,  True,  True, False,  True,  True,\n",
       "       False, False, False, False, False,  True,  True,  True,  True,\n",
       "        True, False, False, False,  True,  True,  True,  True,  True,\n",
       "       False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False,  True,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True,  True,\n",
       "       False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True, False, False,  True,\n",
       "       False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "        True,  True,  True, False,  True, False, False, False, False,\n",
       "        True,  True,  True, False,  True, False, False, False,  True,\n",
       "        True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True, False, False, False,\n",
       "       False,  True, False, False,  True, False,  True,  True, False,\n",
       "        True, False,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as sklearn\n",
    "np.array(test['class']) == predicted_class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_indices = np.array(test['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[134,  13],\n",
       "       [ 87,   4]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.confusion_matrix(true_indices, predicted_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        'id': pd.Series(test_generator.filenames), \n",
    "        'label': pd.Series(predicted_class_indices)\n",
    "    })\n",
    "results_df['id'] = results_df.id.str.extract('(\\d+)')\n",
    "results_df['id'] = pd.to_numeric(results_df['id'], errors = 'coerce')\n",
    "results_df.sort_values(by='id', inplace = True)\n",
    "\n",
    "results_df.to_csv('submission.csv', index=False)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
