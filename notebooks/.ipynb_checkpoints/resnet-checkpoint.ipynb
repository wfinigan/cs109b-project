{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed for our Cats & Dogs classes\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Fixed for Cats & Dogs color images\n",
    "CHANNELS = 3\n",
    "\n",
    "IMAGE_RESIZE = 224\n",
    "RESNET50_POOLING_AVERAGE = 'avg'\n",
    "DENSE_LAYER_ACTIVATION = 'softmax'\n",
    "OBJECTIVE_FUNCTION = 'binary_crossentropy'\n",
    "\n",
    "# Common accuracy metric for all outputs, but can use different metrics for different output\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
    "NUM_EPOCHS = 20\n",
    "#EARLY_STOP_PATIENCE = 3\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\n",
    "STEPS_PER_EPOCH_TRAINING = 24\n",
    "STEPS_PER_EPOCH_VALIDATION = 24\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\n",
    "BATCH_SIZE_TRAINING = 32\n",
    "BATCH_SIZE_VALIDATION = 32\n",
    "\n",
    "# Using 1 to easily manage mapping between test_generator & prediction for submission preparation\n",
    "BATCH_SIZE_TESTING = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Still not talking about our train/test data or any pre-processing.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
    "model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = resnet_weights_path))\n",
    "\n",
    "# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
    "model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
    "\n",
    "# Say not to train first layer (ResNet) model as it is already trained\n",
    "model.layers[0].trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import optimizers\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = IMAGE_RESIZE\n",
    "\n",
    "# preprocessing_function is applied on each image but only after re-sizing & augmentation (resize => augment => pre-process)\n",
    "# Each of the keras.application.resnet* preprocess_input MOSTLY mean BATCH NORMALIZATION (applied on each batch) stabilize the inputs to nonlinear activation functions\n",
    "# Batch Normalization helps in faster convergence\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../clean_data/mass/train/resnet_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   path  class\n",
       "0           0  0.tif      1\n",
       "1           1  1.tif      1\n",
       "2           2  2.tif      0\n",
       "3           3  3.tif      0\n",
       "4           4  4.tif      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 621 images belonging to 2 classes.\n",
      "Found 155 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# flow_From_directory generates batches of augmented data (where augmentation can be color conversion, etc)\n",
    "# Both train & valid folders must have NUM_CLASSES sub-folders\n",
    "\n",
    "train_generator = data_generator.flow_from_dataframe(train,\n",
    "                                                     directory = '../clean_data/mass/train/crops/',\n",
    "                                                     x_col = 'path',\n",
    "                                                     y_col = 'class',\n",
    "                                                     target_size= (image_size, image_size),\n",
    "                                                     batch_size = BATCH_SIZE_TRAINING,\n",
    "                                                     class_mode = 'categorical',\n",
    "                                                     subset = 'training')\n",
    "\n",
    "validation_generator = data_generator.flow_from_dataframe(train,\n",
    "                                                     directory = '../clean_data/mass/train/crops/',\n",
    "                                                     x_col = 'path',\n",
    "                                                     y_col = 'class',\n",
    "                                                     target_size= (image_size, image_size),\n",
    "                                                     batch_size = BATCH_SIZE_TRAINING,\n",
    "                                                     class_mode = 'categorical',\n",
    "                                                     subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max number of steps that these generator will have opportunity to process their source content\n",
    "# len(train_generator) should be 'no. of available train images / BATCH_SIZE_TRAINING'\n",
    "# len(valid_generator) should be 'no. of available train images / BATCH_SIZE_VALIDATION'\n",
    "#(BATCH_SIZE_TRAINING, len(train_generator), BATCH_SIZE_VALIDATION, len(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping & checkpointing the best model in ../working dir & restoring that as our model for prediction\n",
    "# from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n",
    "# cb_checkpointer = ModelCheckpoint(filepath = 'best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.grid_search import ParameterGrid\\nparam_grid = {'epochs': [5, 10, 15], 'steps_per_epoch' : [10, 20, 50]}\\n\\ngrid = ParameterGrid(param_grid)\\n\\n# Accumulate history of all permutations (may be for viewing trend) and keep watching for lowest val_loss as final model\\nfor params in grid:\\n    print(params)\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search is an ideal candidate for distributed machine learning\n",
    "# Pseudo code for hyperparameters Grid Search\n",
    "\n",
    "'''\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "param_grid = {'epochs': [5, 10, 15], 'steps_per_epoch' : [10, 20, 50]}\n",
    "\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "# Accumulate history of all permutations (may be for viewing trend) and keep watching for lowest val_loss as final model\n",
    "for params in grid:\n",
    "    print(params)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13/24 [===============>..............] - ETA: 5s - loss: 1.0198 - acc: 0.5129"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "        #callbacks=[cb_checkpointer, cb_early_stopper]\n",
    ")\n",
    "model.load_weights(\"best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_test = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('clean_data/mass/test/resnet_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE that flow_from_directory treats each sub-folder as a class which works fine for training data\n",
    "# Actually class_mode=None is a kind of workaround for test data which too must be kept in a subfolder\n",
    "\n",
    "# batch_size can be 1 or any factor of test dataset size to ensure that test dataset is samples just once, i.e., no data is left out\n",
    "test_generator = data_generator.flow_from_dataframe(test,\n",
    "                                                     directory = '../clean_data/mass/test/crops/',\n",
    "                                                     x_col = 'path',\n",
    "                                                     y_col = 'class',\n",
    "                                                     target_size= (image_size, image_size),\n",
    "                                                     batch_size = BATCH_SIZE_TRAINING,\n",
    "                                                     class_mode = 'categorical')\n",
    "\n",
    "# Try batch size of 1+ in test_generator & check batch_index & filenames in resulting batches\n",
    "'''\n",
    "for i in test_generator:\n",
    "    #print(test_generator.batch_index, test_generator.batch_size)\n",
    "    idx = (test_generator.batch_index - 1) * test_generator.batch_size\n",
    "    print(test_generator.filenames[idx : idx + test_generator.batch_size])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 386ms/step\n"
     ]
    }
   ],
   "source": [
    "# Reset before each call to predict\n",
    "test_generator.reset()\n",
    "\n",
    "pred = model.predict_generator(test_generator, steps = len(test_generator), verbose = 1)\n",
    "\n",
    "predicted_class_indices = np.argmax(pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False,  True,  True, False, False,  True,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False,  True,  True,  True,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "       False, False, False,  True,  True,  True, False,  True,  True,\n",
       "       False, False, False, False, False,  True,  True,  True,  True,\n",
       "        True, False, False, False,  True,  True,  True,  True,  True,\n",
       "       False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False,  True,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True,  True,\n",
       "       False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True, False, False,  True,\n",
       "       False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "        True,  True,  True, False,  True, False, False, False, False,\n",
       "        True,  True,  True, False,  True, False, False, False,  True,\n",
       "        True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True, False, False, False,\n",
       "       False,  True, False, False,  True, False,  True,  True, False,\n",
       "        True, False,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as sklearn\n",
    "np.array(test['class']) == predicted_class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_indices = np.array(test['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[134,  13],\n",
       "       [ 87,   4]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.confusion_matrix(true_indices, predicted_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        'id': pd.Series(test_generator.filenames), \n",
    "        'label': pd.Series(predicted_class_indices)\n",
    "    })\n",
    "results_df['id'] = results_df.id.str.extract('(\\d+)')\n",
    "results_df['id'] = pd.to_numeric(results_df['id'], errors = 'coerce')\n",
    "results_df.sort_values(by='id', inplace = True)\n",
    "\n",
    "results_df.to_csv('submission.csv', index=False)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
